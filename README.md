# Data Cleaning & Standardization Pipeline

## Overview
This project demonstrates an end-to-end data cleaning and standardization workflow similar to real-world Data Operations processes.

The pipeline:
- Collects raw candidate data
- Cleans missing and inconsistent values
- Removes duplicates
- Standardizes formats (email, date)
- Validates data fields
- Stores cleaned data in SQL database
- Executes SQL queries for validation and analytics

## Technologies Used
- Python
- Pandas
- NumPy
- SQLite (SQL inside Python)

## Key Features
- Missing value handling
- Duplicate removal
- Data format standardization
- Data validation checks
- SQL integration for data storage
- Aggregation and filtering queries

## Files
- raw_candidate_data.csv
- cleaned_candidate_data.csv
- Data_Cleaning_Pipeline.ipynb

## Learning Outcome
This project demonstrates data cleaning, standardization, validation, and database integration processes used in data operations and machine learning data preparation workflows.
